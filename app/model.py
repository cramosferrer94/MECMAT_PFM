# app/model.pyimport pandas as pdimport osimport jsonimport pickleimport numpy as npfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegressionfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score# PathsHISTORICAL_CSV = "app/HISTORICAL DATA.csv"PRODUCTION_CSV = "app/PRODUCTION TIMES.csv"MODEL_DIR = "model"MODEL_PATH = os.path.join(MODEL_DIR, "LR_schedule_model.pkl")METRICS_PATH = os.path.join(MODEL_DIR, "metrics.json")def train_model():    # Upload csv files    historical_data = pd.read_csv("app/HISTORICAL DATA.csv")    production_times = pd.read_csv("app/PRODUCTION TIMES.csv")        # Convert DEMAND_DATE from object to datetime format    historical_data["DEMAND_DATE"] = pd.to_datetime(historical_data["DEMAND_DATE"]).dt.to_period("M").astype(str)        # Merge datasets (left join) on PROD_ID    merged_data = historical_data.merge(production_times, on="PROD_ID", how="left")        # Total Monthly Production Time by Product (minutes)    merged_data["TOTAL_TIME"] = merged_data["DEMAND_QUANT"] * merged_data["PROD_TIME"]        # Extract Temporal Features    merged_data["DEMAND_DATE"] = pd.to_datetime(merged_data["DEMAND_DATE"], format="%Y-%m")    merged_data["YEAR"] = merged_data["DEMAND_DATE"].dt.year    merged_data["MONTH"] = merged_data["DEMAND_DATE"].dt.month        # Calculate Historical Average Demand per Product    prod_avg_demand = merged_data.groupby("PROD_ID")["DEMAND_QUANT"].mean().to_dict()    merged_data["PROD_AVG_DEMAND"] = merged_data["PROD_ID"].map(prod_avg_demand)        # Target Variable    merged_data["TARGET"] = merged_data.groupby("PROD_ID")["DEMAND_QUANT"].shift(-1)        # Create lagged feature    merged_data["lag1"] = merged_data.groupby("PROD_ID")["DEMAND_QUANT"].shift(1)        # Moving Average 3 & 6 months    merged_data["moving_avg_3"] = merged_data.groupby("PROD_ID")["DEMAND_QUANT"].transform(lambda a: a.rolling(window=3).mean())    merged_data["moving_avg_6"] = merged_data.groupby("PROD_ID")["DEMAND_QUANT"].transform(lambda a: a.rolling(window=6).mean())        # Delete rows with NaN values    merged_data = merged_data.dropna()        # Variables Definition & Dataset Division    features = ["YEAR", "MONTH", "TIRE_SALES", "PROD_AVG_DEMAND", "lag1", "moving_avg_3", "moving_avg_6"]    X = merged_data[features]    y = merged_data["TARGET"]        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)        # Prediction on Test Dataset    model = LinearRegression()    model.fit(X_train, y_train)        # Test Evaluation    y_pred = model.predict(X_test)    mae = mean_absolute_error(y_test, y_pred)    rmse = np.sqrt(mean_squared_error(y_test, y_pred))    last_date = pd.to_datetime(historical_data["DEMAND_DATE"], format="%Y-%m").max()    if last_date.month == 12:        r2 = r2_score(y_test, y_pred)    else:        if os.path.exists(METRICS_PATH):            with open(METRICS_PATH, "r") as f:                last_metrics = json.load(f)                r2 = last_metrics.get("r2", None)        else:            r2 = None        # Save model & metrics    os.makedirs(MODEL_DIR, exist_ok=True)    with open(MODEL_PATH, "wb") as f:        pickle.dump(model, f)    metrics = {"mae": round(float(mae),4), "rmse": round(float(rmse),4), "r2": round(float(r2),4)}    with open(METRICS_PATH, "w") as f:        json.dump(metrics, f)    print(f"Model saved to {MODEL_PATH}")    print(f"Metrics saved to {METRICS_PATH}: {metrics}")        return model, metricsdef load_metrics():    if os.path.exists(METRICS_PATH):        with open(METRICS_PATH) as f:            return json.load(f)    return {}def get_trained_model():    if os.path.exists(MODEL_PATH) and os.path.exists(METRICS_PATH):        with open(MODEL_PATH, "rb") as f:            return pickle.load(f)    return train_model()